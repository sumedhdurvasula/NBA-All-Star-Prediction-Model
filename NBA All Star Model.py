# -*- coding: utf-8 -*-
"""Notebook 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uX1d-cTt4ouMIHLh-SdYKB5Hf0AeeJRS

## Upload CSV file
"""

!pip install mlxtend

!pip install imblearn
!pip install xgboost

import pandas as pd
import sklearn
from imblearn.over_sampling import BorderlineSMOTE
import numpy as np
from matplotlib import pyplot as plt
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier as XGBC
import pickle
from imblearn.over_sampling import ADASYN
from sklearn.model_selection import GridSearchCV

nba_data = pd.read_csv("Cleaned_Data.csv")
from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from sklearn.linear_model import LinearRegression

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

nba_data

graph_nba_data = nba_data.iloc[:654]
allstars = graph_nba_data[graph_nba_data['all_star'] == True]
nonallstars = graph_nba_data[graph_nba_data['all_star'] == False]
xlabel = 'player_id'
ylabels = ['pts_per_game', 'x3p_percent']
ylabel = 'pts_per_game'
plt.scatter(allstars[xlabel], allstars[ylabel], color='red', label = 'allstar')
plt.scatter(nonallstars[xlabel], nonallstars[ylabel], color='blue', label = 'nonallstar')
plt.xlabel(xlabel)
plt.ylabel(ylabel)

nba_data = pd.read_csv("Cleaned_Data.csv")

droppedSet = nba_data.drop(nba_data.columns[0], axis = 1)
X = droppedSet.drop(["all_star","player_id","player","season","seas_id", "conf"], 1)       # feature matrix

y = nba_data['all_star']

#forward feature selection
sfs = SFS(LinearRegression(),
          k_features=6,
          forward=True,
          floating=False,
          scoring = 'r2',
          cv = 7)


sfs.fit(X, y)

sfs.k_feature_names_

import random

def get_train_test(data, test_size):
    global train
    global test
    train_years = list(range(1980,2023))
    test_years = []
    for i in range(test_size):
        year = random.choice(train_years)
        train_years.remove(year)
        test_years.append(year)

    train = data.loc[data['season'].isin(train_years)]
    test = data.loc[data['season'].isin(test_years)]

    print("Test Seasons:")
    print(test_years)
    print("Train Season:" )
    print(train_years)

    # return (train_years, test_years)

get_train_test(nba_data, 6)

"""# Random Forest"""

allFeatures = ['x3p_percent','pts_per_game','ast_per_game','blk_per_game', 'ws','per', 'pts', 'ast','trb']

X = nba_data[["ws", "x3p_percent", "blk_per_game", "trb", "per", "pts", 'ast', 'pts_per_game', 'ast_per_game']]

# train_years, test_years = get_train_test(X, 6)

y = nba_data['all_star']

testdf = nba_data[nba_data['season'] == 2023]
Xtest = testdf[["ws", "x3p_percent", "blk_per_game", "trb", 'pts_per_game']]
ytest = testdf['all_star']

traindf = nba_data[nba_data['season'] != 2023]
Xtrain = traindf[["ws", "x3p_percent", "blk_per_game", "trb", 'pts_per_game']]
ytrain = traindf['all_star']

parameters = {
'n_estimators': 60,
'max_features': 0.5,
'min_samples_leaf': 10,
}

rf = RandomForestClassifier(max_features=.5, n_estimators=60, min_samples_leaf=10)

'''
grid_search = GridSearchCV(
estimator=rf,
param_grid=parameters,
scoring = 'accuracy',
n_jobs = 10,
cv = 5,
verbose=True)'''
sm = SMOTE(random_state=10)

Xtrain, ytrain = sm.fit_resample(Xtrain, ytrain)
#grid_search.fit(Xtrain, ytrain)
rf.fit(Xtrain, ytrain)

#print(grid_search.best_params_)
#predictions = grid_search.best_estimator_.predict(Xtest)

predictions = rf.predict(Xtest)

confusionmatrix = confusion_matrix(ytest, predictions)
tn, fp, fn, tp = confusionmatrix.ravel()

ConfusionMatrixDisplay(confusionmatrix).plot();
#pd.set_option('display.max_rows', None)
result_df_randomforest = (pd.concat([(testdf[testdf['all_star'] == True])['player'], (pd.DataFrame(predictions, columns=['prediction'])[testdf['all_star'] == True])], 1)).drop_duplicates(subset='player')
#pred_all_stars = pd.DataFrame(predictions, columns=['all_star'])
#pred_all_stars = pred_all_stars[pred_all_stars['all_star'] == True]
#players = pd.DataFrame(testdf['player'])
#displayframe = pd.concat([players, pred_all_stars, predictions], 1)
#displayframe = displayframe.dropna(subset=['all_star'])

#display(displayframe)


sklearn.metrics.RocCurveDisplay.from_predictions(ytest, predictions)
plt.show()

print("Accuracy Score: ", round(accuracy_score(ytest, predictions) * 100, 3), "%")
print("Precision Score: ", round(precision_score(ytest, predictions) * 100, 3), "%")
print("Recall Score: ", round(recall_score(ytest, predictions) * 100, 3), "%")

display(result_df_randomforest)

pred_all_stars = pd.DataFrame(predictions, columns=['all_star'])
pred_all_stars = pred_all_stars[pred_all_stars['all_star'] == True]
players = pd.DataFrame(testdf['player'])

df1 = pd.concat([players, pred_all_stars], 1)
df1 = df1.dropna(subset=['all_star']).drop_duplicates()

df2 = pd.concat([players, ytest], 1)
mask = df2['all_star'].isin([True])
df2 = df2[mask].drop_duplicates()

display(df1)

"""# Neural Network"""

allFeatures = ['x3p_percent','pts_per_game','ast_per_game','blk_per_game', 'ws','per', 'pts', 'ast','trb']

X = nba_data[["ws", "x3p_percent", "blk_per_game", "trb", "per", "pts", 'ast', 'pts_per_game', 'ast_per_game']]


y = nba_data['all_star']

testdf = nba_data[nba_data['season'] == 2023]
Xtest = testdf[["ws", "x3p_percent", "blk_per_game", "trb", 'pts_per_game']]
ytest = testdf['all_star']

traindf = nba_data[nba_data['season'] != 2023]
Xtrain = traindf[["ws", "x3p_percent", "blk_per_game", "trb", 'pts_per_game']]
ytrain = traindf['all_star']

# sm = SMOTE(random_state=10)
# Xtrain, ytrain = sm.fit_resample(Xtrain, ytrain)

ada = ADASYN(random_state=42)
Xtrain, ytrain = ada.fit_resample(Xtrain, ytrain)



#rf = RandomForestClassifier()
#rf.fit(Xtrain, ytrain)
#predictions = rf.predict(Xtest)

NN = MLPClassifier(hidden_layer_sizes=(130, 100, 50), max_iter=300, activation='relu', solver='sgd', random_state=1)
NN.fit(Xtrain, ytrain)

predictions = NN.predict(Xtest)

confusionmatrix = confusion_matrix(ytest, predictions)

ConfusionMatrixDisplay(confusionmatrix).plot();

result_df_nn = (pd.concat([(testdf[testdf['all_star'] == True])['player'], (pd.DataFrame(predictions, columns=['prediction'])[testdf['all_star'] == True])], 1)).drop_duplicates(subset='player')
#pd.set_option('display.max_rows', None)
# display(pd.concat([testdf['player'], pd.DataFrame(predictions, columns=['all_star']), ytest], 1))
#all_stars = pd.DataFrame(predictions, columns=['all_star'])
#all_stars = all_stars[all_stars['all_star'] == True]
#players = pd.DataFrame(testdf['player'])
#displayframe = pd.concat([players, all_stars], 1)
#displayframe = displayframe.dropna(subset=['all_star'])

#display(displayframe)

sklearn.metrics.RocCurveDisplay.from_predictions(ytest, predictions)
plt.show()

print("Accuracy Score: ", round(accuracy_score(ytest, predictions) * 100, 3), "%")
print("Precision Score: ", round(precision_score(ytest, predictions) * 100, 3), "%")
print("Recall Score: ", round(recall_score(ytest, predictions) * 100, 3), "%")

result_df_nn

X = nba_data[["ws", "x3p_percent", "blk_per_game", "trb", "per", "pts", 'ast', 'pts_per_game', 'ast_per_game']]


y = nba_data['all_star']

testdf = nba_data[nba_data['season'] == 2023]
Xtest = testdf[["ws", "x3p_percent", "blk_per_game", "trb", 'pts_per_game']]
ytest = testdf['all_star']

predictions = NN.predict(Xtest)

confusionmatrix = confusion_matrix(ytest, predictions)

ConfusionMatrixDisplay(confusionmatrix).plot();

x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])
y = np.array([0.917557251908397, 0.9206106870229007, 0.9435114503816794, 0.9526717557251908, 0.9603053435114504, 0.9587786259541985, 0.9557251908396946, 0.9572519083969465, 0.9557251908396946])
yXGB = np.array([.9040,.8945,.906,.921,.916,.92567,.9351,.9391,.928])
plt.xticks(x)
plt.xlabel("Number of Features")
plt.ylabel("Accuracy")
plt.plot(x, yXGB)
plt.show

pred_all_stars = pd.DataFrame(predictions, columns=['all_star'])
pred_all_stars = pred_all_stars[pred_all_stars['all_star'] == True]
players = pd.DataFrame(testdf['player'])

df1 = pd.concat([players, pred_all_stars], 1)
df1 = df1.dropna(subset=['all_star']).drop_duplicates()

df2 = pd.concat([players, ytest], 1)
mask = df2['all_star'].isin([True])
df2 = df2[mask].drop_duplicates()

display(df1)

"""# XGBoost"""

# # Create a list of unique seasons in your dataset
# seasons = nba_data['season'].unique()

# # Initialize an empty list to store model performance results
# results = []

# # Iterate through the seasons
# for i in range(1, len(seasons) - 2):
#     # train_season = seasons[i]
#     # test_season = seasons[i + 1]
#     test_season = i

#     # Create training and test datasets based on the seasons
#     Xtrain = nba_data[nba_data['season'] != test_season][["ws", "x3p_percent", "blk_per_game", "trb", "per"]]
#     Xtest = nba_data[nba_data['season'] == test_season][["ws", "x3p_percent", "blk_per_game", "trb", "per"]]
#     ytrain = nba_data[nba_data['season'] != test_season]['all_star']
#     ytest = nba_data[nba_data['season'] == test_season]['all_star']

#     # Apply SMOTE to balance the training data (assuming you have imbalanced classes)
#     sm = SMOTE(random_state=10)

#     Xtrain, ytrain = sm.fit_resample(Xtrain, ytrain)

#     # Train a Random Forest Classifier
#     rf = RandomForestClassifier()
#     rf.fit(Xtrain, ytrain)

#     # Make predictions on the test set
#     predictions = rf.predict(Xtest)

#     # Evaluate model performance for the current season
#     # You can use metrics like accuracy, precision, recall, F1-score, etc.
#     accuracy = accuracy_score(ytest, predictions)
#     precision = precision_score(ytest, predictions)
#     recall = recall_score(ytest, predictions)

#     # Store the results for this season
    # results.append({
    #     'Train Season': train_season,
    #     'Test Season': test_season,
    #     'Accuracy': accuracy,
    #     'Precision': precision,
    #     'Recall': recall
    # })

# # Print or analyze the results as needed
# for result in results:
#     print(result)



allFeatures = ['x3p_percent','pts_per_game','ast_per_game','blk_per_game', 'ws','per', 'pts', 'ast','trb']

unique_seasons = nba_data['season'].unique()
print(len(unique_seasons))
results = []

for season in range(0, len(unique_seasons) - 2):  # Exclude the latest season for testing
    testdf = nba_data[nba_data['season'] == season]
    traindf = nba_data[nba_data['season'] != season]

    Xtrain = traindf[allFeatures]
    ytrain = traindf['all_star']

    Xtest = testdf[allFeatures]
    ytest = testdf['all_star']

    parameters = {
    'max_depth': range (2, 10, 3),
    'n_estimators': range(60, 220, 80),
    'learning_rate': np.arange(.01, .1, .01)
    }
    ada = ADASYN(random_state=42, sampling_strategy='minority')
    Xtrain, ytrain = ada.fit_resample(Xtrain, ytrain)

    xgbc = XGBC()

    grid_search = GridSearchCV(
    estimator=xgbc,
    param_grid=parameters,
    scoring = 'accuracy',
    n_jobs = 10,
    cv = 5,
    verbose=True)

    xgbc.fit(Xtrain_resampled, ytrain_resampled)



    predictions = xgbc.predict(Xtest)
    confusion_matrix_result = confusion_matrix(ytest, predictions)

    results.append({
        'Test Season': season,
        'Accuracy': accuracy_score(ytest, predictions),
        'Precision': precision_score(ytest, predictions),
        'Recall': recall_score(ytest, predictions)
    })

for result in results:
    print(result)

allFeatures = ['x3p_percent','pts_per_game','ast_per_game','blk_per_game', 'ws','per', 'pts', 'ast','trb']

testdf1 = nba_data[nba_data['season'] == 2023]
traindf = nba_data[nba_data['season'] != 2023]

Xtrain = traindf[allFeatures]
ytrain = traindf['all_star']

Xtest = testdf1[allFeatures]
ytest = testdf1['all_star']

sm = SMOTE(random_state=10)
Xtrain_resampled, ytrain_resampled = sm.fit_resample(Xtrain, ytrain)

# ada = ADASYN(random_state=42, sampling_strategy='minority')
# Xtrain_resampled, ytrain_resampled = ada.fit_resample(Xtrain, ytrain)

parameters = {
'max_depth': 8,
'n_estimators': 140,
'learning_rate': 0.09
}


xgbc = XGBC(**parameters)
'''
grid_search = GridSearchCV(
estimator=xgbc,
param_grid=parameters,
scoring = 'accuracy',
n_jobs = 10,
cv = 10,
verbose=True)

grid_search.fit(Xtrain_resampled, ytrain_resampled)'''
xgbc.fit(Xtrain_resampled, ytrain_resampled)
#print(grid_search.best_params_)
predictions1 = xgbc.predict(Xtest)
confusionmatrix = confusion_matrix(ytest, predictions1)
tn, fp, fn, tp = confusionmatrix.ravel()
print(tp)

ConfusionMatrixDisplay(confusionmatrix).plot();

predictions1 = np.where(predictions1 == 1, True, False)

pd.set_option('display.max_rows', None)

result_df = pd.concat([
    (testdf1[testdf1['all_star'] == True]['player']),
    pd.DataFrame(predictions1, columns=['prediction'])[testdf1['all_star'] == True]
], axis=1)

# Drop duplicate players
result_df = result_df.drop_duplicates(subset='player')

# Display the result
print(result_df)
display((pd.concat([(testdf1[testdf1['all_star'] == True])['player'], (pd.DataFrame(predictions1, columns=['prediction'])[testdf1['all_star'] == True])], 1)).drop_duplicates(subset='player'))
#actual_all_stars_df = testdf[testdf['all_star'] == True][['player']]
#actual_all_stars_df['Predicted_All_Star'] = predictions[actual_all_stars_df.index] == 1

#print(actual_all_stars_df)


#display(result_df)


sklearn.metrics.RocCurveDisplay.from_predictions(ytest, predictions1)
plt.show()

print("Accuracy Score: ", round(accuracy_score(ytest, predictions1) * 100, 3), "%")
print("Precision Score: ", round(precision_score(ytest, predictions1) * 100, 3), "%")
print("Recall Score: ", round(recall_score(ytest, predictions1) * 100, 3), "%")

display(result_df)

"""<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e9ae238f-55ac-4c86-a74a-4f87062ad280' target="_blank">
<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>
Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>
"""